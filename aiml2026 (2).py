# -*- coding: utf-8 -*-
"""aiml2026.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EkJ-amvrmymBHXHAxx_KJqcytZxiCst2

COLAB DI GAIA BIANCO, ALESSANDRO CORTI, ROBERTA MIRAGLIA E ANTONIETTA TODISCO
"""

!pip install torch transformers sentence-transformers scikit-learn pandas numpy tqdm rank_bm25 pyarrow -q

import os
import zipfile
import urllib.request

DATASET_URL = "https://github.com/fabsilvestri/aiml_hackathon_data/releases/download/v1.0/kaggle_data.zip"
DATA_DIR = "data"

print("Downloading dataset...")
urllib.request.urlretrieve(DATASET_URL, "kaggle_data.zip")
os.makedirs(DATA_DIR, exist_ok=True)
with zipfile.ZipFile("kaggle_data.zip", "r") as zf:
    zf.extractall(DATA_DIR)
os.remove("kaggle_data.zip")
print("Dataset ready!")

import pandas as pd
import random

test_queries = pd.read_csv(f"{DATA_DIR}/test.csv")
collection = pd.read_parquet(f"{DATA_DIR}/collection.parquet")
ts = pd.read_parquet(f"{DATA_DIR}/train.parquet")
vs = pd.read_parquet(f"{DATA_DIR}/val.parquet")
all_pids = collection["pid"].astype(str).tolist()

print(f"Loaded {len(test_queries)} test queries and {len(all_pids)} passages.")

"""Librerie utili:"""

import tensorflow as tf
from tensorflow.keras import layers
import numpy as np
import sentence_transformers
import torch
import numpy
import rank_bm25

"""Visualizziamo i dataframe:"""

test_queries.head()

collection.head()

ts.head()

"""Trasformiamo i dataframe in liste con una funzione:"""

def df2list(df):
  return df.values.tolist()

"""Preparazione dati:"""

tqlist = df2list(test_queries)
clist = df2list(collection)
tqdict = {tqlist[i][0] : tqlist[i][1] for i in range(len(tqlist))}
cdict = {clist[i][0] : clist[i][1] for i in range(len(clist))}
qlist = df2list(test_queries['query'])
plist = df2list(collection['passage'])
qidslist = df2list(test_queries["id"])
pidslist = df2list(collection["pid"])

"""Funzioni che fanno il ranking:"""

import pandas as pd
from sentence_transformers import SentenceTransformer, CrossEncoder, util
from tqdm import tqdm

# --- CONFIGURAZIONE ---
# Sostituisci con i tuoi dati reali
queries = qlist  # Simula 4912 query
passaggi = plist # Simula 65000 passaggi

device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Utilizzando: {device}")

# --- 1. CARICAMENTO MODELLI ---
# Bi-Encoder per il retrieval veloce
bi_encoder = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1', device=device)
# Cross-Encoder per il ranking di alta qualit√†
cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2', device=device)

# --- 2. EMBEDDING DEI PASSAGGI ---
print("Generazione embeddings per i passaggi...")
corpus_embeddings = bi_encoder.encode(
    passaggi,
    batch_size=64,
    show_progress_bar=True,
    convert_to_tensor=True
)

# --- 3. RETRIEVAL E RERANKING ---
results = []

print("Elaborazione query...")
for query in tqdm(queries):
    # FASE A: Bi-Encoder Retrieval (Top 100)
    query_embedding = bi_encoder.encode(query, convert_to_tensor=True)
    hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=100)[0]

    # Prepara i dati per il Cross-Encoder
    passage_indices = [hit['corpus_id'] for hit in hits]
    cross_inputs = [[query, passaggi[idx]] for idx in passage_indices]

    # FASE B: Cross-Encoder Reranking
    cross_scores = cross_encoder.predict(cross_inputs, batch_size=128, show_progress_bar=False)

    # Combina e ordina
    for i in range(len(hits)):
        hits[i]['score'] = cross_scores[i]
        hits[i]['text'] = passaggi[hits[i]['corpus_id']]

    # Prendi i Top 10 definitivi
    hits = sorted(hits, key=lambda x: x['score'], reverse=True)[:10]
    results.append({"query": query, "top_10": hits})

# --- 4. SALVATAGGIO ---
# Esempio di visualizzazione del primo risultato
print("\nTop 1 Risultato per la prima query:")
print(f"Query: {results[0]['query']}")
print(f"Passaggio: {results[0]['top_10'][0]['text']} (Score: {results[0]['top_10'][0]['score']:.4f})")

result_ids = []
for d in results:
  result_ids.append([d["query"], [d["top_10"][i]['text'] for i in range(10)]])
result_ids[2]
out = []
tqdict_inv = {v: k for k, v in tqdict.items()}
cdict_inv = {v: k for k, v in cdict.items()}
for q, ps in result_ids:
  x = []
  for p in ps:
    x.append(cdict_inv[p])
  out.append([tqdict_inv[q], ' '.join(x)])
out[1]

# --- 4. SALVATAGGIO FILE ---
results_df = pd.DataFrame(out, columns = ['id', 'expected'])

# Controlli rapidi
print(f"\nRighe generate: {len(results_df)}")
print("Esempio prime righe:")
print(results_df.head())

# Salvataggio su disco
results_df.to_csv("submission.csv", index=False)
print("File 'submission.csv' salvato correttamente.")